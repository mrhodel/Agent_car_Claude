# ──────────────────────────────────────────────────────────────────
#  Yahboom Raspbot V2  ·  Agent Configuration
#  All physical pin / I2C settings can be overridden here so that
#  no hardware constant is buried inside Python source code.
# ──────────────────────────────────────────────────────────────────

robot:
  name: "RaspbotV2"
  wheel_type: mecanum          # mecanum | differential
  max_speed: 80                # motor duty-cycle limit  0-100
  min_speed: 20                # below this motors stall

# ── Hardware Abstraction Layer ────────────────────────────────────
hal:
  motor:
    driver: yahboom             # yahboom | simulation
    i2c_bus: 1
    i2c_address: 0x2B          # Yahboom expansion board I2C address (PI5Car_I2CADDR)
    max_speed: 80               # duty-cycle cap passed to YahboomBoard

  ultrasonic:
    # The HC-SR04 is a FIXED front-facing sensor on the chassis.
    # It connects to the Yahboom expansion board (NOT to RPi GPIO).
    # The gimbal is for the CAMERA only – it does not move the ultrasonic.
    i2c_bus: 1
    i2c_address: 0x2B          # same expansion board as motors/servos
    max_range_cm: 400
    min_range_cm: 8            # hardware blind spot: < ~7.2 cm returns 400/garbage; add margin
    samples_per_reading: 3     # median filter over N acquisitions

  gimbal:
    # Servos driven by the Yahboom expansion board via I2C.
    # Servo 1 = pan (horizontal), Servo 2 = tilt (vertical).
    # No PCA9685 or direct GPIO – everything through the board.
    driver: yahboom             # yahboom | simulation
    i2c_bus: 1
    i2c_address: 0x2B          # same expansion board as motors/ultrasonic
    pan_range: [-90, 90]       # degrees from centre
    tilt_range: [-45, 30]
    tilt_neutral: 30           # raw servo angle (0-180) that points camera level
    move_speed_deg_s: 120      # max angular velocity (software-limited)

  camera:
    # Raspbot V2 ships with a 1MP USB camera on the 2-DOF gimbal.
    # The primary driver is 'usb' (OpenCV VideoCapture / V4L2).
    # 'picamera2' is only needed if a CSI module is fitted instead.
    driver: usb                # usb | picamera2 | simulation
    device_index: 0            # USB video device index
    width: 640
    height: 480
    fps: 30
    auto_exposure: true
    # Optional MJPEG stream for remote monitoring
    stream_port: 8080
    stream_enabled: false

# ── Perception ────────────────────────────────────────────────────
perception:
  vision:
    input_size: [224, 224]     # fed into feature extractor
    feature_dim: 128           # MobileNetV2 bottleneck output
    device: cpu                # cpu | cuda (RPi → cpu)

  depth:
    model: midas_small         # midas_small | midas_v21 | none
    output_size: [16, 16]      # downsampled depth map fed to RL
    # If model=none, a simple stereo-disparity proxy is used
    normalize: true

  obstacle:
    confidence_threshold: 0.50
    nms_iou_threshold: 0.45
    min_pixel_area: 500        # ignore tiny detections
    danger_zone_px: 80         # bottom strip height = "floor boundary"

  floor:
    method: edge_color         # edge_color | homography
    hsv_floor_low:  [0,  0,  80]
    hsv_floor_high: [180, 50, 255]
    boundary_rows: 0.55        # fractions of frame height

  objects:
    model: yolov5n             # yolov5n | yolov5s | mobilenet_ssd
    weights: models/yolov5n.pt
    classes_of_interest: [0, 56, 57, 58, 59, 60, 62, 63, 64, 67]
    # 0=person, 56-67=furniture/household (COCO)

  sensor_fusion:
    us_weight: 0.60
    cam_weight: 0.40
    history_window: 5          # frames retained for temporal smoothing

# ── Mapping ───────────────────────────────────────────────────────
mapping:
  grid:
    resolution_m: 0.05         # metres per cell
    initial_size_cells: 200    # 200×200 → 10 m × 10 m  (faster; expands if needed)
    expand_threshold: 20       # grow when robot < N cells from edge
    expand_amount: 100
    inflate_interval: 10       # run gaussian obstacle inflation every N steps (0=disabled)
    p_prior: 0.50
    p_occ_hit:  0.75
    p_occ_miss: 0.40
    p_occ_min:  0.05
    p_occ_max:  0.95
    obstacle_threshold: 0.65   # cell probability → obstacle
    free_threshold: 0.35
    blur_sigma: 0.8            # Gaussian inflation around obstacles
    decay_rate: 0.001          # per-step probability decay toward prior

# ── Navigation ────────────────────────────────────────────────────
navigation:
  planner:
    algorithm: astar           # astar | dijkstra
    heuristic: euclidean       # euclidean | manhattan | diagonal
    safety_margin_cells: 2     # keep away from obstacles by N cells
    max_plan_length: 500       # cells; replan if path exceeds
    path_smoothing: true
    smoothing_iterations: 3

  controller:
    lookahead_dist_m: 0.20     # pure-pursuit lookahead
    goal_tolerance_m: 0.10
    angle_kp: 1.2
    linear_kp: 0.8
    max_angular_vel: 60        # motor duty-cycle units
    max_linear_vel: 70

  recovery:
    spin_degrees: 30
    backup_duration_s: 0.5
    max_attempts: 5

# ── Reinforcement Learning ────────────────────────────────────────
rl:
  state:
    # The ultrasonic sensor is FIXED (single forward reading = 1 value).
    # Increasing this to >1 uses a temporal window of past readings.
    ultrasonic_rays: 1         # 1 = current reading only
    visual_feature_dim: 128
    depth_map_flat: 256        # 16×16
    local_map_size: 7          # 7×7 window around robot
    include_velocity: true     # [v_x, v_y, omega]
    include_heading: true      # sin(θ), cos(θ)

  actions:
    # 0-5 → base motion, 6-9 → gimbal, 10 → stop
    names: [forward, backward, strafe_left, strafe_right,
            rotate_left, rotate_right, gimbal_pan_left,
            gimbal_pan_right, gimbal_tilt_up, gimbal_tilt_down, stop]
    base_speed: 55             # duty cycle for forward
    strafe_speed: 30           # lower = fewer cm/step sideways (no side sensors)
    reverse_speed: 30          # lower = fewer cm/step backward (no rear sensor)
    rotate_speed: 45
    gimbal_step_deg: 10
    # Safety pre-checks for blind directions (robot mode only)
    spin_180_duration_s: 0.7   # timed spin to face rear before reversing; tune on floor
    side_depth_close: 0.75     # depth map value (0-1, higher=closer) above which strafe blocked

  reward:
    exploration_bonus: 1.0     # per newly-revealed cell
    goal_reached: 50.0
    collision_penalty: -15.0
    proximity_penalty_scale: -0.5  # ×(1/dist) when dist < 30 cm
    time_step_cost: -0.01
    smooth_motion_bonus: 0.05  # penalise jerk

  ppo:
    learning_rate: 3.0e-4
    gamma: 0.99
    gae_lambda: 0.95
    clip_epsilon: 0.2
    value_loss_coeff: 0.5
    entropy_coeff: 0.01
    epochs_per_update: 4
    batch_size: 64
    rollout_steps: 512         # sim training
    hardware_rollout_steps: 64  # robot training (update ~every 1 min of real movement)
    hidden_dim: 256
    max_steps_per_episode: 500  # cap episode length during training
    checkpoint_dir: models/checkpoints
    checkpoint_interval: 10   # episodes (works for both sim and hardware)

# ── Agent Orchestrator ────────────────────────────────────────────
agent:
  loop_hz: 10                  # main control loop frequency
  safety:
    emergency_stop_cm: 10      # unconditional halt if anything < N cm
    low_battery_voltage: 6.8   # volts (if voltage monitor available)
  exploration:
    frontier_min_size: 3       # minimum frontier cells to pursue
    rescan_interval_s: 5.0     # full gimbal sweep period
    gimbal_scan_steps: 9       # pan positions during sweep
  logging:
    level: INFO                # DEBUG | INFO | WARNING
    log_dir: logs/
    save_map_interval_s: 30
